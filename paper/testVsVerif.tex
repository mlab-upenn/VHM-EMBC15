\subsection{Testing vs Verification}

\newcommand{\ub}{\bar{u}}
\newcommand{\yb}{\bar{y}}

\emph{\textbf{Testing}} is a method for checking that a system does indeed obey its specification. 
In testing, an algorithm will 
\begin{itemize}
	\item initialize the system to some initial state $x_0$ in $X_0$.
	E.g., for a pacemaker device, this would describe the initial values for the various refractory periods, among other things.
	\item Generate sequences of input strings $\bar{u}_k$ from some set $A$, in reaction to which the system will produce output strings $\bar{y}_k$,
	\item a \emph{monitor} logs the output strings and determines whether the pair $(\bar{u}_k,\bar{y}_k)$ satisfies the specification or not.	
\end{itemize}

Because the set of valid initial states $X_0$ and the set of valid input strings $A$ may be infinite (or simply too large), the testbench must decide on how to intelligently choose a \emph{finite} number of $(x_0,\ub)$.
They must be chosen such that if the system does not produce wrong behavior with these pairs, then it is unlikely to produce errors under the \emph{full} valid set of pairs, namely, $X_0 \times A$.
This is the main challenge of testing: how to sample an infinite or large set of behaviors such that it is representative (in the above sense) of the full set of behaviors that $S$ is capable of?
Another important issue in testing is for how long to test the system: i.e. what should be the length of the $k^{th}$ string $\ub_k$? 
E.g., if $\ub_k$ has length 1000, the bug might manifest itself on $y_1\ldots y_{1001}$, but not $y_1\ldots y_{1000}$.

Regardless of testing algorithm, testing remains incomplete, in the sense that short of testing every possible behavior, bugs may lie hidden in the behavior that we did not witness.

\emph{\textbf{Verification}} refers to formal verification.
It is applicable to finite state systems\footnote{Some infinite-state systems can be formally verified after an abstraction process which essentially produces an equivalent system that has finitely many states.}, 
and requires formal semantics for the system's operation. 
Roughly, this means we must have a mathematical unambiguous definition of how the system produces its output.
A verification algorithm, or \emph{model checker}, will explore the \emph{entire finite state-space} of the system in a systematic manner. 
Intuitively, if the entire state-space has been explored in all possible ways, and no incorrect behavior has been displayed, then the system is correct. 
Thus, verification is inherently \emph{complete}: if the model checker determines that the system is correct (under the conditions $A$ and $X_0$), then we can rest assured that that is indeed the case.
Unlike testing, there is no question of whether we missed (didn't run) an initial condition that can display a bug.
There is also no question of test duration.
However in practice, some bound on the duration of the verification must be placed to avoid excessively long runs. 
If the model checker can't determine correctness in that time bound, then the verification is inconclusive.

Verification is computationally expensive and usually more burdensome to setup, but comes with a guarantee on the answer. 
Testing is computationally cheaper and less burdensome to setup, but the guarantees it provides are significantly weaker.
Testing, on the other hand, may be the only option for some complex systems that are beyond the capacity of today's model checkers, or which do not possess formal semantics.






